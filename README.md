# Spirits Scraper v2.2 - Catalog-Focused Edition ğŸš€

A high-efficiency Node.js spirits scraper that achieves **10+ spirits per API call** by intelligently mining retailer catalog pages instead of searching for individual products.

## ğŸŒŸ What's New in v2.2

### 100x Efficiency Improvement!
- **OLD METHOD**: 0.11 spirits per API call (searching for individual products)
- **NEW METHOD**: 10+ spirits per API call (mining catalog pages)
- **HOW**: Searches for retailer catalog pages and extracts ALL products at once

### Real Example
```bash
# OLD: Searching for "Buffalo Trace Kosher Bourbon 750 ml"
# Result: 1 product from 1 API call (if lucky)

# NEW: Searching for site:totalwine.com "Buffalo Trace"
# Result: 50+ products from 1 API call!
```

## Features

- ğŸš€ **Catalog-Focused Scraping** - Extract 10+ spirits per API call
- ğŸ“¦ **908 Distilleries** - Comprehensive coverage across all spirit types
- ğŸ” **Smart Extraction** - Gets complete product listings from catalogs
- ğŸ¯ **Targeted Retailers** - Focuses on high-yield sites like TotalWine
- ğŸ“Š **Efficiency Metrics** - Real-time spirits-per-API-call tracking
- ğŸ’¾ **Redis Caching** - Avoids duplicate API calls
- ğŸ”„ **Auto-Deduplication** - Merges duplicates automatically
- âœ¨ **Enhanced Data** - ABV, age, region, cask type extraction
- ğŸ“ˆ **Quality Scoring** - 0-100 quality score for each spirit
- ğŸ›¡ï¸ **Smart Validation** - Filters out reviews and non-products

## Quick Start

```bash
# Install
npm install

# Configure environment
cp .env.example .env
# Add your API keys to .env

# Run the NEW high-efficiency catalog scraper
npm run scrape-catalogs

# Or target specific distilleries
npm run scrape-catalogs -- --distilleries "Buffalo Trace,Wild Turkey"
```

## Catalog Scraping Examples

### Scrape All Distilleries (908 total)
```bash
npm run scrape-catalogs
# Processes all 908 distilleries using catalog pages
# Expects 10,000+ spirits with just 1,000 API calls!
```

### Scrape Specific Distilleries
```bash
npm run scrape-catalogs -- --distilleries "Buffalo Trace,Macallan,Glenfiddich"
# Gets complete product catalogs for these distilleries
```

### Control Product Limits
```bash
npm run scrape-catalogs -- --max-products 200
# Get up to 200 products per distillery
```

### Resume Interrupted Scraping
```bash
npm run scrape-catalogs -- --start-index 100
# Resume from distillery #100
```

## How Catalog Scraping Works

1. **Searches Retailer Catalogs**: `site:totalwine.com "Buffalo Trace"`
2. **Extracts Product Grid**: Finds all products on the page
3. **Parallel Processing**: Hits multiple retailers simultaneously
4. **Smart Extraction**: Gets name, price, description from listings
5. **Bulk Storage**: Stores all products from one search

## Efficiency Comparison

| Method | Example Query | Products Found | API Calls | Efficiency |
|--------|--------------|----------------|-----------|------------|
| Old | "Buffalo Trace Kosher Bourbon 750ml" | 1 | 1 | 1.0 |
| Old | "Eagle Rare 10 Year price" | 0-1 | 1 | 0.5 |
| **NEW** | site:totalwine.com "Buffalo Trace" | 50+ | 1 | **50+** |
| **NEW** | site:masterofmalt.com "Macallan" | 75+ | 1 | **75+** |

## All Commands

### Primary Commands (Use These!)
```bash
# ğŸš€ HIGH EFFICIENCY - Catalog scraping (10+ spirits/call)
npm run scrape-catalogs
npm run scrape-catalogs -- --distilleries "Buffalo Trace"

# Regular smart scraping (1-3 spirits/call)
npm run scrape -- --categories bourbon --limit 50

# Remove duplicates
npm run dedup

# View statistics
npm run stats
```

### Additional Commands
```bash
# Backup/restore
npm run backup
npm run backup -- --restore <id>

# Cache management
npm run cache -- --stats
npm run cache -- --clear

# Fix existing data
npm run fix-csv input.csv output.csv

# Dry-run deduplication analysis
npm run dry-run
```

## Prerequisites

- Node.js 18+
- Google Cloud Platform account with Custom Search API
- Supabase project for data storage
- Redis instance (Upstash recommended)

## Configuration

Create `.env` file:
```env
# Google Search API
GOOGLE_API_KEY=your_google_api_key
SEARCH_ENGINE_ID=your_search_engine_id

# Supabase
SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_KEY=your_service_key

# Redis (Upstash)
UPSTASH_REDIS_REST_URL=your_redis_url
UPSTASH_REDIS_REST_TOKEN=your_redis_token
```

## Architecture

### Catalog-Focused Design
- **catalog-focused-scraper.ts** - Searches retailer catalogs
- **Multi-product extraction** - Gets all products from search results
- **Retailer targeting** - Prioritizes high-yield sites
- **Efficiency tracking** - Real-time metrics

### Service Architecture
```
src/services/
â”œâ”€â”€ catalog-focused-scraper.ts  # NEW! High-efficiency catalog scraper
â”œâ”€â”€ spirit-extractor.ts         # Enhanced data extraction
â”œâ”€â”€ deduplication-service.ts    # Automatic duplicate merging
â”œâ”€â”€ cache-service.ts           # Redis caching layer
â””â”€â”€ supabase-storage.ts        # Database operations
```

### Distillery Coverage
- ğŸ¥ƒ **Bourbon**: 79 distilleries
- ğŸ´ó§ó¢ó³ó£ó´ó¿ **Scotch**: 266 distilleries
- ğŸŒµ **Tequila**: 181 distilleries
- ğŸï¸ **Rum**: 142 distilleries
- ğŸ¸ **Gin**: 52 distilleries
- ğŸ¾ **Vodka**: 41 distilleries
- ğŸ¥ƒ **American Craft**: 94 distilleries
- ğŸ· **Cognac**: 53 distilleries

## Performance Optimization

### Why Catalog Scraping is Superior
1. **Bulk Extraction**: Get 50+ products from one search
2. **Structured Data**: Retailers have consistent formats
3. **Complete Listings**: No missing products
4. **Price Data**: Most catalog pages show prices
5. **Fresh Inventory**: Retailer pages are always current

### Tips for Maximum Efficiency
- Clear cache before major scraping: `npm run cache -- --clear`
- Use specific distilleries for testing
- Monitor efficiency with `npm run stats`
- Run deduplication after large batches

## Development

```bash
# Build TypeScript
npm run build

# Run tests
npm test

# Lint code
npm run lint

# Type checking
npm run typecheck
```

## API Rate Limits

- Google Search API: 100 queries/day (free tier)
- With catalog scraping: 100 queries = 1,000+ spirits!
- Automatic rate limit detection
- Caching prevents duplicate API calls

## Expected Output

```
ğŸš€ Starting CATALOG-FOCUSED scraping...

ğŸ“‹ Processing: Buffalo Trace
ğŸ” Searching: site:totalwine.com "Buffalo Trace"
ğŸ“¦ Found 52 products from this catalog search
âœ… Stored: Buffalo Trace Kentucky Straight Bourbon
âœ… Stored: Buffalo Trace Kosher Wheat Recipe
âœ… Stored: Eagle Rare 10 Year
... 49 more products
ğŸ“Š Efficiency: 52.00 spirits per API call

ğŸ“Š SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ­ Distilleries processed: 5
ğŸ¥ƒ Total products found: 423
ğŸ’¾ Total products stored: 387
ğŸ“ˆ Overall efficiency: 21.15 spirits per API call
```

## Troubleshooting

### Low Efficiency?
```bash
# Clear cache for fresh searches
npm run cache -- --clear

# Check which retailers work best
npm run site-metrics
```

### Too Many Duplicates?
```bash
# Run deduplication
npm run dedup

# Preview first
npm run dedup -- --dry-run
```

### API Limit Reached?
```bash
# Check remaining quota
npm run stats

# Use cached results only
npm run scrape -- --cache-only
```

## Contributing

1. Fork the repository
2. Create feature branch
3. Test with small batches first
4. Submit pull request

## License

MIT

---

**Remember**: With catalog scraping, every API call counts! Target retailer catalogs for maximum efficiency. ğŸš€